{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "inspect_apple_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kRIpa146yzQp",
        "0Jxyi07cyzQt",
        "u1b4PYLlyzQ4",
        "VH5eL2npyzQ8",
        "xAL8iDrsyzRB",
        "bTBEkvGYyzRD",
        "bV9xRaEmyzRI",
        "7u-MCm8yyzRN",
        "cxZpsa0uyzRP"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carrie86/Project_maskrcnn/blob/main/inspect_apple_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwcGSf4SyzQE"
      },
      "source": [
        "# Mask R-CNN - Inspect Apple Trained Model\n",
        "\n",
        "Code and visualizations to test, debug, and evaluate the Mask R-CNN model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWxSym3ByzQF",
        "outputId": "f69c45e7-2dab-4f60-8e83-f599676f72d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!pip install tqdm\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnyVbLBvzaM6",
        "outputId": "4903161c-1e92-4cfc-b8bb-a2f4887c1e8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX4b4MvK0Nx3",
        "outputId": "6d59a5df-30ae-4d5e-d314-79736b7d40a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Pro_apple"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Pro_apple\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx1AAGds0NpH",
        "outputId": "bf69020f-f567-4849-ca7b-45d747b88145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ae0SuLX0Ncp",
        "outputId": "0250e445-3795-4ed5-c483-e743a912f902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Pro_apple/Mask_RCNN/samples/apple"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Pro_apple/Mask_RCNN/samples/apple\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHLdVxOe_UrM",
        "outputId": "f9d0be14-7389-4260-8619-b8590d5e3267",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.18.5)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 50.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.12.4)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.35.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.33.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.0) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.3.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.3.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=c21757e14ba02d90d2550be0778abea2a66383b9e78377c80d79d337d298b07d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBchq4v-0RZ3",
        "outputId": "e76cc17c-d8d4-4fef-8953-78bc6f25511e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install keras==2.3.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.1\n",
            "  Using cached https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVaBnO7q4ClI",
        "outputId": "e1d79259-9007-45d9-c775-26815aaa1326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!install content/drive/My Drive/Pro_apple/Mask_RCNN/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "install: cannot stat 'content/drive/My': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YZ15rr8DHdn",
        "outputId": "19a1f573-1450-43c0-c329-d8b7070b52ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Pro_apple/Mask_RCNN/samples/apple"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Pro_apple/Mask_RCNN/samples/apple\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S3EeTruN9RF",
        "outputId": "50ed0521-42b8-4b52-9629-e841009e7e0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/64/b28bf154ef1ee5b1e1978816e80d54f462a3e22e7c67cfdbf7ebada5abfe/wandb-0.10.8-py2.py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/36/afa3c32f61cb62bef0da7200651d41f36b8b069d9f6254d8df8a20b224b8/sentry_sdk-0.19.2-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 38.2MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/08/b2/ef713e0e67f6e7ec7d59aea3ee78d05b39c15930057e724cc6d362a8c3bb/configparser-5.0.1-py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 18.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (50.3.2)\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, watchdog, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=72b13c819508169737e0aa86f6fe7882e8f5517bb2dbd695360cd5c0179802db\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73873 sha256=f9d37138328bfc658edf08a40f12d20336a217b9777dea35e2790368a0ab339e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=1008c2235cd04d8480fb334238a24330b96c8da2eac156ce9ebaf167a46a697c\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 watchdog pathtools\n",
            "Installing collected packages: docker-pycreds, subprocess32, sentry-sdk, configparser, smmap, gitdb, GitPython, shortuuid, pathtools, watchdog, wandb\n",
            "Successfully installed GitPython-3.1.11 configparser-5.0.1 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 sentry-sdk-0.19.2 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.10.8 watchdog-0.10.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "configparser",
                  "wandb"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIhC5nWVPGUZ",
        "outputId": "7cbd0a89-b061-42e6-a94f-a858a12b4fc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Pro_apple/Mask_RCNN/samples/apple"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Pro_apple/Mask_RCNN/samples/apple\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEmYiSfTOhS3",
        "outputId": "3094886a-3b7b-4bd4-b65f-9809f263db0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wandb login d72b44fadcf6d4ea71e979875a5169e4c3efd698"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19zklV04OsPl",
        "outputId": "151fb7c1-b608-4315-eb52-c0b660f239a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import wandb\n",
        "!wandb.init(project=\"apple_diseases_detection\",name=f\"{datetime.datetime.now()}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `project=\"apple_diseases_detection\",name=f\"{datetime.datetime.now()}\"'\n",
            "/bin/bash: -c: line 0: `wandb.init(project=\"apple_diseases_detection\",name=f\"{datetime.datetime.now()}\")'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ravtVyhIyzQJ",
        "outputId": "c863ab17-7284-4b01-9206-f39c02b36243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../../\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "from samples.apple import apple\n",
        "#from samples.apple.apple_wandb import apple\n",
        "from tqdm import tqdm #<추가\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "print(MODEL_DIR)\n",
        "\n",
        "# Path to Ballon trained weights\n",
        "# You can download this file from the Releases page\n",
        "# https://github.com/matterport/Mask_RCNN/releases\n",
        "APPLE_WEIGHTS_PATH = os.path.join(MODEL_DIR,\"apple20201103T1133/mask_rcnn_apple_0093.h5\")  # TODO: update this path\n",
        "print(APPLE_WEIGHTS_PATH)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-f38c14124745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapple\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#from samples.apple.apple_wandb import apple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;31m#<추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'samples.apple'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyXltVrJyzQL"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-OSEdZNyzQM",
        "outputId": "eb9595e2-ae20-4bd6-d3d4-344a27831928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "config = apple.AppleConfig()\n",
        "APPLE_DIR = os.path.join(ROOT_DIR, \"samples/apple/dataset\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-ae0fe60e3ada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAppleConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mAPPLE_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"samples/apple/dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'apple' has no attribute 'AppleConfig'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZYD90PuyzQO"
      },
      "source": [
        "# Override the training configurations with a few\n",
        "# changes for inferencing.\n",
        "class InferenceConfig(config.__class__):\n",
        "    # Run detection on one image at a time\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    IMAGE_MAX_DIM = 1024\n",
        "#     BACKBONE= \"resnet50\"\n",
        "#     DETECTION_MIN_CONFIDENCE = 0.9\n",
        "#     IMAGE_MAX_DIM =1024\n",
        "#     IMAGE_MIN_DIM =512\n",
        "#     IMAGE_RESIZE_MODE = \"square\"\n",
        "#     LAYER_STAGE =\"3+\"\n",
        "#     LEARNING_RATE =0.01\n",
        "#     OPTIMIZER =\"SGD\"\n",
        "#     ROI_POSITIVE_RATIO =0.4\n",
        "#     RPN_NMS_THRESHOLD =0.5\n",
        "#     STEPS_PER_EPOCH =200\n",
        "#     TRAIN_BN = True\n",
        "#     TRAIN_ROIS_PER_IMAGE = 300\n",
        "#     VALIDATION_STEPS =50\n",
        "#     WEIGHT_DECAY =0.01\n",
        "#     RPN_ANCHOR_SCALES =(32, 64, 128, 256, 512)\n",
        "    \n",
        "config = InferenceConfig()\n",
        "config.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQEtv49LyzQQ"
      },
      "source": [
        "## Notebook Preferences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INkuXjY1yzQR"
      },
      "source": [
        "# Device to load the neural network on.\n",
        "# Useful if you're training a model on the same \n",
        "# machine, in which case use CPU and leave the\n",
        "# GPU for training.\n",
        "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0 --> cpu:0이 cpu지정\n",
        "\n",
        "# Inspect the model in training or inference modes\n",
        "# values: 'inference' or 'training'\n",
        "# TODO: code for 'training' test mode not ready yet\n",
        "TEST_MODE = \"inference\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z58Lz9xAyzQW"
      },
      "source": [
        "def get_ax(rows=1, cols=1, size=16):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Adjust the size attribute to control how big to render images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuGzQNmayzQZ"
      },
      "source": [
        "dataset = apple.AppleDataset()\n",
        "dataset.image_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT3eck8_yzQb"
      },
      "source": [
        "## Load Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiMToIMhyzQc"
      },
      "source": [
        "# Load validation dataset\n",
        "dataset = apple.AppleDataset()\n",
        "dataset.load_apple(APPLE_DIR, \"val\")\n",
        "\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEvVWH4nyzQe"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIC16HHcyzQf"
      },
      "source": [
        "# Create model in inference mode\n",
        "with tf.device(DEVICE):\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
        "                              config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "nYiquNZpyzQh"
      },
      "source": [
        "# Set path to balloon weights file\n",
        "\n",
        "# Download file from the Releases page and set its path\n",
        "# https://github.com/matterport/Mask_RCNN/releases\n",
        "# weights_path = \"/path/to/mask_rcnn_balloon.h5\"\n",
        "\n",
        "# Or, load the last model you trained\n",
        "weights_path = model.find_last()\n",
        "\n",
        "# Load weights\n",
        "print(\"Loading weights \", APPLE_WEIGHTS_PATH)\n",
        "model.load_weights(APPLE_WEIGHTS_PATH, by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQ8-xYZyzQj"
      },
      "source": [
        "## Run Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRoeVZXkyzQj"
      },
      "source": [
        "\n",
        "image_id = random.choice(dataset.image_ids)\n",
        "#3: Bitter rot, 50: sooty_blotch, 57:flyspeck, 35: white rot, 12:Viroid , 67: Bitter pit, 75:Brown rot, 25:Scab\n",
        "#target = [3,50,57,35,12,67,75,25]\n",
        "target = [3,50,35,75,25]\n",
        "#image_id = random.choice(target)\n",
        "print(\"image_id: \",image_id)\n",
        "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
        "info = dataset.image_info[image_id]\n",
        "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
        "                                       dataset.image_reference(image_id)))\n",
        "\n",
        "# Run object detection\n",
        "results = model.detect([image], verbose=1)\n",
        "\n",
        "# Display results\n",
        "\n",
        "ax = get_ax(1)\n",
        "r = results[0]\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset.class_names, r['scores'], ax=ax,\n",
        "                            title=\"Predictions\")\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5BBLyqbyzQl"
      },
      "source": [
        "## Color Splash\n",
        "\n",
        "This is for illustration. You can call `balloon.py` with the `splash` option to get better images without the black padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvgmpP-ryzQm"
      },
      "source": [
        "splash = apple.color_splash(image, r['masks'])\n",
        "display_images([splash], cols=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hocEpr5EyzQo"
      },
      "source": [
        "## Step by Step Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT9GCmcAyzQo"
      },
      "source": [
        "## Stage 1: Region Proposal Network\n",
        "\n",
        "The Region Proposal Network (RPN) runs a lightweight binary classifier on a lot of boxes (anchors) over the image and returns object/no-object scores. Anchors with high *objectness* score (positive anchors) are passed to the stage two to be classified.\n",
        "\n",
        "Often, even positive anchors don't cover objects fully. So the RPN also regresses a refinement (a delta in location and size) to be applied to the anchors to shift it and resize it a bit to the correct boundaries of the object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRIpa146yzQp"
      },
      "source": [
        "### 1.a RPN Targets\n",
        "\n",
        "The RPN targets are the training values for the RPN. To generate the targets, we start with a grid of anchors that cover the full image at different scales, and then we compute the IoU of the anchors with ground truth object. Positive anchors are those that have an IoU >= 0.7 with any ground truth object, and negative anchors are those that don't cover any object by more than 0.3 IoU. Anchors in between (i.e. cover an object by IoU >= 0.3 but < 0.7) are considered neutral and excluded from training.\n",
        "\n",
        "To train the RPN regressor, we also compute the shift and resizing needed to make the anchor cover the ground truth object completely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGcJRSKhyzQp",
        "outputId": "73a64331-0b49-431c-c394-5aee5bbadfad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "# Generate RPN trainig targets\n",
        "# target_rpn_match is 1 for positive anchors, -1 for negative anchors\n",
        "# and 0 for neutral anchors.\n",
        "target_rpn_match, target_rpn_bbox = modellib.build_rpn_targets(\n",
        "    image.shape, model.anchors, gt_class_id, gt_bbox, model.config)\n",
        "log(\"target_rpn_match\", target_rpn_match)\n",
        "log(\"target_rpn_bbox\", target_rpn_bbox)\n",
        "\n",
        "positive_anchor_ix = np.where(target_rpn_match[:] == 1)[0]\n",
        "negative_anchor_ix = np.where(target_rpn_match[:] == -1)[0]\n",
        "neutral_anchor_ix = np.where(target_rpn_match[:] == 0)[0]\n",
        "positive_anchors = model.anchors[positive_anchor_ix]\n",
        "negative_anchors = model.anchors[negative_anchor_ix]\n",
        "neutral_anchors = model.anchors[neutral_anchor_ix]\n",
        "log(\"positive_anchors\", positive_anchors)\n",
        "log(\"negative_anchors\", negative_anchors)\n",
        "log(\"neutral anchors\", neutral_anchors)\n",
        "\n",
        "# Apply refinement deltas to positive anchors\n",
        "refined_anchors = utils.apply_box_deltas(\n",
        "    positive_anchors,\n",
        "    target_rpn_bbox[:positive_anchors.shape[0]] * model.config.RPN_BBOX_STD_DEV)\n",
        "log(\"refined_anchors\", refined_anchors, )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d6a7a2fd812a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# and 0 for neutral anchors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m target_rpn_match, target_rpn_bbox = modellib.build_rpn_targets(\n\u001b[0;32m----> 5\u001b[0;31m     image.shape, model.anchors, gt_class_id, gt_bbox, model.config)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"target_rpn_match\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_rpn_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"target_rpn_bbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_rpn_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7Dod_eNyzQr",
        "outputId": "9769f2f4-9c27-4032-edde-741e433302bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Display positive anchors before refinement (dotted) and\n",
        "# after refinement (solid).\n",
        "visualize.draw_boxes(image, boxes=positive_anchors, refined_boxes=refined_anchors, ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-434ff2a5cbab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Display positive anchors before refinement (dotted) and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# after refinement (solid).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvisualize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositive_anchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefined_boxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefined_anchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_ax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jxyi07cyzQt"
      },
      "source": [
        "### 1.b RPN Predictions\n",
        "\n",
        "Here we run the RPN graph and display its predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNLv6BlwyzQt"
      },
      "source": [
        "# Run RPN sub-graph\n",
        "pillar = model.keras_model.get_layer(\"ROI\").output  # node to start searching from\n",
        "\n",
        "# TF 1.4 and 1.9 introduce new versions of NMS. Search for all names to support TF 1.3~1.10\n",
        "nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression:0\")\n",
        "if nms_node is None:\n",
        "    nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression/NonMaxSuppressionV2:0\")\n",
        "if nms_node is None: #TF 1.9-1.10\n",
        "    nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression/NonMaxSuppressionV3:0\")\n",
        "\n",
        "rpn = model.run_graph([image], [\n",
        "    (\"rpn_class\", model.keras_model.get_layer(\"rpn_class\").output),\n",
        "    (\"pre_nms_anchors\", model.ancestor(pillar, \"ROI/pre_nms_anchors:0\")),\n",
        "    (\"refined_anchors\", model.ancestor(pillar, \"ROI/refined_anchors:0\")),\n",
        "    (\"refined_anchors_clipped\", model.ancestor(pillar, \"ROI/refined_anchors_clipped:0\")),\n",
        "    (\"post_nms_anchor_ix\", nms_node),\n",
        "    (\"proposals\", model.keras_model.get_layer(\"ROI\").output),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKt0MRHHyzQv"
      },
      "source": [
        "# Show top anchors by score (before refinement)\n",
        "limit = 100\n",
        "sorted_anchor_ids = np.argsort(rpn['rpn_class'][:,:,1].flatten())[::-1]\n",
        "visualize.draw_boxes(image, boxes=model.anchors[sorted_anchor_ids[:limit]], ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "opE5MyFIyzQx"
      },
      "source": [
        "# Show top anchors with refinement. Then with clipping to image boundaries\n",
        "limit = 100\n",
        "ax = get_ax(1, 2)\n",
        "pre_nms_anchors = utils.denorm_boxes(rpn[\"pre_nms_anchors\"][0], image.shape[:2])\n",
        "refined_anchors = utils.denorm_boxes(rpn[\"refined_anchors\"][0], image.shape[:2])\n",
        "refined_anchors_clipped = utils.denorm_boxes(rpn[\"refined_anchors_clipped\"][0], image.shape[:2])\n",
        "visualize.draw_boxes(image, boxes=pre_nms_anchors[:limit],\n",
        "                     refined_boxes=refined_anchors[:limit], ax=ax[0])\n",
        "visualize.draw_boxes(image, refined_boxes=refined_anchors_clipped[:limit], ax=ax[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "zoC3LzezyzQz"
      },
      "source": [
        "# Show refined anchors after non-max suppression\n",
        "limit = 30\n",
        "ixs = rpn[\"post_nms_anchor_ix\"][:limit]\n",
        "visualize.draw_boxes(image, refined_boxes=refined_anchors_clipped[ixs], ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aAqo1hsyzQ1"
      },
      "source": [
        "# Show final proposals\n",
        "# These are the same as the previous step (refined anchors \n",
        "# after NMS) but with coordinates normalized to [0, 1] range.\n",
        "limit = 100\n",
        "# Convert back to image coordinates for display\n",
        "h, w = config.IMAGE_SHAPE[:2]\n",
        "proposals = rpn['proposals'][0, :limit] * np.array([h, w, h, w])\n",
        "visualize.draw_boxes(image, refined_boxes=proposals, ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEH6CpQLyzQ3"
      },
      "source": [
        "## Stage 2: Proposal Classification\n",
        "\n",
        "This stage takes the region proposals from the RPN and classifies them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1b4PYLlyzQ4"
      },
      "source": [
        "### 2.a Proposal Classification\n",
        "\n",
        "Run the classifier heads on proposals to generate class propbabilities and bounding box regressions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUx4WyBUyzQ4"
      },
      "source": [
        "# Get input and output to classifier and mask heads.\n",
        "mrcnn = model.run_graph([image], [\n",
        "    (\"proposals\", model.keras_model.get_layer(\"ROI\").output),\n",
        "    (\"probs\", model.keras_model.get_layer(\"mrcnn_class\").output),\n",
        "    (\"deltas\", model.keras_model.get_layer(\"mrcnn_bbox\").output),\n",
        "    (\"masks\", model.keras_model.get_layer(\"mrcnn_mask\").output),\n",
        "    (\"detections\", model.keras_model.get_layer(\"mrcnn_detection\").output),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_ffja1zyzQ6"
      },
      "source": [
        "# Get detection class IDs. Trim zero padding.\n",
        "det_class_ids = mrcnn['detections'][0, :, 4].astype(np.int32)\n",
        "det_count = np.where(det_class_ids == 0)[0][0]\n",
        "det_class_ids = det_class_ids[:det_count]\n",
        "detections = mrcnn['detections'][0, :det_count]\n",
        "\n",
        "print(\"{} detections: {}\".format(\n",
        "    det_count, np.array(dataset.class_names)[det_class_ids]))\n",
        "\n",
        "captions = [\"{} {:.3f}\".format(dataset.class_names[int(c)], s) if c > 0 else \"\"\n",
        "            for c, s in tqdm(zip(detections[:, 4], detections[:, 5]))]\n",
        "visualize.draw_boxes(\n",
        "    image, \n",
        "    refined_boxes=utils.denorm_boxes(detections[:, :4], image.shape[:2]),\n",
        "    visibilities=[2] * len(detections),\n",
        "    captions=captions, title=\"Detections\",\n",
        "    ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH5eL2npyzQ8"
      },
      "source": [
        "### 2.c Step by Step Detection\n",
        "\n",
        "Here we dive deeper into the process of processing the detections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLR6ppLSyzQ8"
      },
      "source": [
        "# Proposals are in normalized coordinates. Scale them\n",
        "# to image coordinates.\n",
        "h, w = config.IMAGE_SHAPE[:2]\n",
        "proposals = np.around(mrcnn[\"proposals\"][0] * np.array([h, w, h, w])).astype(np.int32)\n",
        "\n",
        "# Class ID, score, and mask per proposal\n",
        "roi_class_ids = np.argmax(mrcnn[\"probs\"][0], axis=1)\n",
        "roi_scores = mrcnn[\"probs\"][0, np.arange(roi_class_ids.shape[0]), roi_class_ids]\n",
        "roi_class_names = np.array(dataset.class_names)[roi_class_ids]\n",
        "roi_positive_ixs = np.where(roi_class_ids > 0)[0]\n",
        "\n",
        "# How many ROIs vs empty rows?\n",
        "print(\"{} Valid proposals out of {}\".format(np.sum(np.any(proposals, axis=1)), proposals.shape[0]))\n",
        "print(\"{} Positive ROIs\".format(len(roi_positive_ixs)))\n",
        "\n",
        "# Class counts\n",
        "print(list(zip(*np.unique(roi_class_names, return_counts=True))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8R_mdJRyzQ-"
      },
      "source": [
        "# Display a random sample of proposals.\n",
        "# Proposals classified as background are dotted, and\n",
        "# the rest show their class and confidence score.\n",
        "limit = 5\n",
        "ixs = np.random.randint(0, proposals.shape[0], limit)\n",
        "captions = [\"{} {:.3f}\".format(dataset.class_names[c], s) if c > 0 else \"\"\n",
        "            for c, s in tqdm(zip(roi_class_ids[ixs], roi_scores[ixs]))]\n",
        "visualize.draw_boxes(image, boxes=proposals[ixs],\n",
        "                     visibilities=np.where(roi_class_ids[ixs] > 0, 2, 1),\n",
        "                     captions=captions, title=\"ROIs Before Refinement\",\n",
        "                     ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAL8iDrsyzRB"
      },
      "source": [
        "#### Apply Bounding Box Refinement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoGeQxQCyzRB"
      },
      "source": [
        "# Class-specific bounding box shifts.\n",
        "roi_bbox_specific = mrcnn[\"deltas\"][0, np.arange(proposals.shape[0]), roi_class_ids]\n",
        "log(\"roi_bbox_specific\", roi_bbox_specific)\n",
        "\n",
        "# Apply bounding box transformations\n",
        "# Shape: [N, (y1, x1, y2, x2)]\n",
        "refined_proposals = utils.apply_box_deltas(\n",
        "    proposals, roi_bbox_specific * config.BBOX_STD_DEV).astype(np.int32)\n",
        "log(\"refined_proposals\", refined_proposals)\n",
        "\n",
        "# Show positive proposals\n",
        "# ids = np.arange(roi_boxes.shape[0])  # Display all\n",
        "limit = 5\n",
        "ids = np.random.randint(0, len(roi_positive_ixs), limit)  # Display random sample\n",
        "captions = [\"{} {:.3f}\".format(dataset.class_names[c], s) if c > 0 else \"\"\n",
        "            for c, s in tqdm(zip(roi_class_ids[roi_positive_ixs][ids], roi_scores[roi_positive_ixs][ids]))]\n",
        "visualize.draw_boxes(image, boxes=proposals[roi_positive_ixs][ids],\n",
        "                     refined_boxes=refined_proposals[roi_positive_ixs][ids],\n",
        "                     visibilities=np.where(roi_class_ids[roi_positive_ixs][ids] > 0, 1, 0),\n",
        "                     captions=captions, title=\"ROIs After Refinement\",\n",
        "                     ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTBEkvGYyzRD"
      },
      "source": [
        "#### Filter Low Confidence Detections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P0xkhpuyzRE"
      },
      "source": [
        "# Remove boxes classified as background\n",
        "keep = np.where(roi_class_ids > 0)[0]\n",
        "print(\"Keep {} detections:\\n{}\".format(keep.shape[0], keep))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2DmCh-ZyzRG"
      },
      "source": [
        "# Remove low confidence detections\n",
        "keep = np.intersect1d(keep, np.where(roi_scores >= config.DETECTION_MIN_CONFIDENCE)[0])\n",
        "print(\"Remove boxes below {} confidence. Keep {}:\\n{}\".format(\n",
        "    config.DETECTION_MIN_CONFIDENCE, keep.shape[0], keep))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV9xRaEmyzRI"
      },
      "source": [
        "#### Per-Class Non-Max Suppression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3gbwJGNyzRI"
      },
      "source": [
        "# Apply per-class non-max suppression\n",
        "pre_nms_boxes = refined_proposals[keep]\n",
        "pre_nms_scores = roi_scores[keep]\n",
        "pre_nms_class_ids = roi_class_ids[keep]\n",
        "\n",
        "nms_keep = []\n",
        "for class_id in tqdm(np.unique(pre_nms_class_ids)):\n",
        "    # Pick detections of this class\n",
        "    ixs = np.where(pre_nms_class_ids == class_id)[0]\n",
        "    # Apply NMS\n",
        "    class_keep = utils.non_max_suppression(pre_nms_boxes[ixs], \n",
        "                                            pre_nms_scores[ixs],\n",
        "                                            config.DETECTION_NMS_THRESHOLD)\n",
        "    # Map indicies\n",
        "    class_keep = keep[ixs[class_keep]]\n",
        "    nms_keep = np.union1d(nms_keep, class_keep)\n",
        "    print(\"{:22}: {} -> {}\".format(dataset.class_names[class_id][:20], \n",
        "                                   keep[ixs], class_keep))\n",
        "\n",
        "keep = np.intersect1d(keep, nms_keep).astype(np.int32)\n",
        "print(\"\\nKept after per-class NMS: {}\\n{}\".format(keep.shape[0], keep))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DplayzrmyzRK"
      },
      "source": [
        "# Show final detections\n",
        "ixs = np.arange(len(keep))  # Display all\n",
        "# ixs = np.random.randint(0, len(keep), 10)  # Display random sample\n",
        "captions = [\"{} {:.3f}\".format(dataset.class_names[c], s) if c > 0 else \"\"\n",
        "            for c, s in tqdm(zip(roi_class_ids[keep][ixs], roi_scores[keep][ixs]))]\n",
        "visualize.draw_boxes(\n",
        "    image, boxes=proposals[keep][ixs],\n",
        "    refined_boxes=refined_proposals[keep][ixs],\n",
        "    visibilities=np.where(roi_class_ids[keep][ixs] > 0, 1, 0),\n",
        "    captions=captions, title=\"Detections after NMS\",\n",
        "    ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi4fbzQyyzRM"
      },
      "source": [
        "## Stage 3: Generating Masks\n",
        "\n",
        "This stage takes the detections (refined bounding boxes and class IDs) from the previous layer and runs the mask head to generate segmentation masks for every instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u-MCm8yyzRN"
      },
      "source": [
        "### 3.a Mask Targets\n",
        "\n",
        "These are the training targets for the mask branch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlCvpLqbyzRN"
      },
      "source": [
        "display_images(np.transpose(gt_mask, [2, 0, 1]), cmap=\"Blues\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxZpsa0uyzRP"
      },
      "source": [
        "### 3.b Predicted Masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL6W1VdoyzRQ"
      },
      "source": [
        "# Get predictions of mask head\n",
        "mrcnn = model.run_graph([image], [\n",
        "    (\"detections\", model.keras_model.get_layer(\"mrcnn_detection\").output),\n",
        "    (\"masks\", model.keras_model.get_layer(\"mrcnn_mask\").output),\n",
        "])\n",
        "\n",
        "# Get detection class IDs. Trim zero padding.\n",
        "det_class_ids = mrcnn['detections'][0, :, 4].astype(np.int32)\n",
        "det_count = np.where(det_class_ids == 0)[0][0]\n",
        "det_class_ids = det_class_ids[:det_count]\n",
        "\n",
        "print(\"{} detections: {}\".format(\n",
        "    det_count, np.array(dataset.class_names)[det_class_ids]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daH3MuC5yzRR"
      },
      "source": [
        "# Masks\n",
        "det_boxes = utils.denorm_boxes(mrcnn[\"detections\"][0, :, :4], image.shape[:2])\n",
        "det_mask_specific = np.array([mrcnn[\"masks\"][0, i, :, :, c] \n",
        "                              for i, c in tqdm(enumerate(det_class_ids))])\n",
        "det_masks = np.array([utils.unmold_mask(m, det_boxes[i], image.shape)\n",
        "                      for i, m in tqdm(enumerate(det_mask_specific))])\n",
        "log(\"det_mask_specific\", det_mask_specific)\n",
        "log(\"det_masks\", det_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r16sCTjdyzRT"
      },
      "source": [
        "display_images(det_mask_specific[:4] * 255, cmap=\"Blues\", interpolation=\"none\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30TlbqzfyzRW"
      },
      "source": [
        "display_images(det_masks[:4] * 255, cmap=\"Blues\", interpolation=\"none\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg9T3qcLyzRY"
      },
      "source": [
        "## Visualize Activations\n",
        "\n",
        "In some cases it helps to look at the output from different layers and visualize them to catch issues and odd patterns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "7Fx9TiYlyzRY"
      },
      "source": [
        "# # Get activations of a few sample layers\n",
        "# activations = model.run_graph([image], [\n",
        "#     (\"input_image\",        tf.identity(model.keras_model.get_layer(\"input_image\").output)),\n",
        "#     (\"res2c_out\",          model.keras_model.get_layer(\"res2c_out\").output),\n",
        "#     (\"res3c_out\",          model.keras_model.get_layer(\"res3c_out\").output),\n",
        "#     (\"res4w_out\",          model.keras_model.get_layer(\"res4w_out\").output),  # for resnet100\n",
        "#     (\"rpn_bbox\",           model.keras_model.get_layer(\"rpn_bbox\").output),\n",
        "#     (\"roi\",                model.keras_model.get_layer(\"ROI\").output),\n",
        "# ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XNlmLiMyzRa"
      },
      "source": [
        "# # Input image (normalized)\n",
        "# _ = plt.imshow(modellib.unmold_image(activations[\"input_image\"][0],config))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMHmRa1eyzRb"
      },
      "source": [
        "# # Backbone feature map\n",
        "# display_images(np.transpose(activations[\"res2c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}